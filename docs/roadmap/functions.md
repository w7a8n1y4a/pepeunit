# Дорожная карта для Pepeunit

## 0.7.0 Система агрегации данных

### Текущее состояние системы
1. Авторизация для подписки и публикации в топики идёт через python, это делается через rest, с хорошей производительностью
    - рест автоматически раскидывается на отдельные воркеры
    - у emqx брокера есть кеширование для авторизаций
2. Есть 2 вида топиков
    - example.com/+/+/+/pepeunit - системные, они забронированы и их поведение стандартизировано в pepeunit
        - Идёт сохранение стандартизированного состояния, обновляются состояния обновлений и тд.
        - Выполняется одним потоком Uvicorn
        - Для топика state сохранение идёт в Postgres
        - Для топика log сохранение идёт в Clickhouse и обновляется время в Postgres
    - example.com/+/pepeunit - принадлежащие Unit
        - Прямое сохранение всего что выдают Unit, в виде текста в Postgres
        - В бд сохраняется только 1 запрос за N секунд по умолчанию 30
3. Общий лимит на обьём информации передаваемой в payload топика берётся из настроек
4. Выполняется одним потоком Uvicorn. Практический потолок 4к запросов в секунду

### Проектное состояние
1. Авторизация остаётся без изменений
2. example.com/+/+/+/pepeunit остаётся в python, разрешаем сохранять не чаще чем лимит `backend_state_send_interval - 1` сек
3. example.com/+/pepeunit переходит в go приложение
    - Go приложение поддерживает одно клиентское соединение и подписано на все топики вида example.com/+/pepeunit
    - Обрабатывает запросы согласно политикам, которые постоянно синхронизируется с python бекендом
4. Связка python + go должна иметь следующие политики накопления данных:
    - По умолчанию все политики выключенны и агрегаци и/или сохранение не идёт, такие топики скипаются всегда. Пользователь должен сам своими руками включить.
    - Сохранение 1 сообщения раз в N сек в Postgres, просто обновляется 1 и то же поле
    - Хранение последних N записей в Clickhouse - накопление событий или ещё чего-то для важных топиков
    - Хранение всех записей за послдение 0-N часов/минут в Clickhouse, с указанием буферизацией от 1 минуты до N часов, чтобы не дудосить
    - Агрегацция с заданной шириной окна агрегации 0-N часов/минут в Clickhouse
        - Привязка должна идти к целым часам. 00:00-00:05 для 5 минут или 00:00-01:00 для 1 часа
        - Идёт буферизация за указанное время, до следующего времени после чего происходит вычисление:
            - min/max
            - sum
            - avg
    - Сохранение данных из JSON
5. Политики могут быть разные по времени:
    - Диапазон времени по датам с часами и минутами
    - Постоянными
5. На стороне python должна быть возможность получать данные от разных типов агрегации через запросы в Clickhouse с пагинациями по времени

## Изменение хранения публичных Repo из github и gitlab
Создаётся repository_regestry:
- uuid
- тип внешнего хранилища
- ссылка на источник
- время создания
- статус синхронизации
- текст ошибки
- время последней синхронизации

1. Все публичные репозитории мигрируют из Repo в repository_regestry
1. Данные в repository_regestry обновляются каждый N часов, с возможностью полного отключения этой функции
1. Админ может принудительно заставить обновиться все репозитории
1. Пользователь может нажать обновление у подконтрольного репозитория

### Приватных репозитории
Всё остаётся как раньше, они хранятся в единичном экземпляре для каждого repo отдельно и не попадают в repository_regestry

### Публичные репозитории
Хранятся на инстансе физически в единственном экземпляре

- нужно проверить можно ли читать файлы множество раз через gitpython, от этого будет зависеть реализация, копирование или подмена uuid
- ссылка на репозиторий будет уникальным ключом

### Ожидаение

1. У Repo будет плашка последнего обновления, его статуса и ошибки. Для публичных repository_regestry, для приватных эти поля появятся в repo
2. Кнопка создания репозитория будет подменена, на кнопку поиска существующих репозиториев
3. Хорошо бы парсить Description и некоторые базовае поля из readme.md для улучшенного поиска по публичным репозиториям
4. Фикс проблемы github в интеграционных тестах
5. Обновлены сами Интеграционные тесты

## Анализ динамического состояния узла

1. Анализ общего числа сообщений поступающих на бэкенд
    - mqtt
    - gql
    - rest
    - aiogram
1. Трекер занятых ресурсов - cpu, ram
1. Оставшееся место
1. Аптайм
1. Трекер ошибок, какие возникают чаще, а какие реже
1. Трекер алерт крашей, с дросселированием - в телегу админу, надо запоминать сколько раз возник

## Анализ нагрузки

На эти метрики будет опираться монетизация и настройки пользователей

1. Система отслеживания нагрузки на топики Unit - Расчёт желательно на стороне EMQX
1. Система отслеживания средней нагрузки на один Unit - Метрика загрузки для repo
1. Метрикой должен быть MPS - запросы в секунду
1. Нужна автоматическая отсечка, если Unit превысил лимиты

## Алерты 
1. Нужно установить начиная с какого уровня лога, будет отправляться alert
1. Дросселирование в телеграм должно работать через Backend, а значит нужна пременная, регламентирующая расстояние между алертами в телеге
1. EMQX должен пересылать алерты на определённый тип ошибок, на основе Rule Engine

## Система бордов

1. Интеграция с Графана, с возможностью авторизовываться через существующий аккаунт
1. Нужны базовые борды для админа - динамическое состояние, анализ нагрузки, трекинг ошибок
1. Нужна возможность конфижить борды с фронта, по пользовательским инициативам, этот функционал должен быть продублирован хотябы частично в телегу

## Монетизация для держателей инстансов

1. Подключаемая монетизация на основе Telegram и криптовалют
1. Основана должна быть на нагрузке от Unit, который создаёт юзер
1. Возможность настройки монетизации для администратора
1. Агригируещие топики должны быть монетизированы с другой политикой, т.к. они несут накладные расходы на хранение данных

## Система грейдов инстансов

1. Добавить итеративность в проверку нагрузки
1. Добавить хэш в отчёт, чтобы было сложнее его поменять
1. Отчёт по нагрузке должен предоставляться по спец запросу load_limit
1. Число бесплатных MPS
1. Стоймость MPS всверх бесплатных
1. Число бесплатных топиков с агрегацией (нужно придумать метрику)
1. Стоймость за один топик с агрегацией (нужно придумать метрику)
1. Токен доступа для скрапера генерит Админ инстанса

## Федерация

TODO: требуется крепкая проработка

1. Федеративный хаб Repo, c поиском по Unit на мультиинстансе
1. Внедрение activity pub
1. Система взаимодействия между инстансами
1. Проработать activity pub
1. Проработать bridge y emqx, до разных инстансов
1. Белые и чёрные листы доменов для создания repo
1. Импорт экспорт всех данных учётной записи по запросу Пользователя
1. Добавить кнопку обновления env от pepeunit, для будущей возможности переноса Unit на другие инстансы
1. Проработать условия автоматического бана внешних инстансов
1. Нужен бан топиков от внешних инстансов, по условиям (выдумать условия)

## Видео для документации
1. Нужно видео по развёртыванию Pepeunit
1. Нужно видео где с 0 на уже развёрнутом инстансе, создаётся готовая система по существующим Repo - от лица Пользователя
1. Нужно видео где с 0 на уже развёрнутом инстансе, разработчик Unit последовательно создёт новый Unit с 0 - от лица разработчика Unit