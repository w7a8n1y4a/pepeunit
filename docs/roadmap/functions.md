# Дорожная карта для Pepeunit

## 0.7.0 Система агрегации данных

### Текущее состояние системы
1. Авторизация для подписки и публикации в топики идёт через python, это делается через rest, с хорошей производительностью
    - рест автоматически раскидывается на отдельные воркеры
    - у emqx брокера есть кеширование для авторизаций
2. Есть 2 вида топиков
    - example.com/+/+/+/pepeunit - системные, они забронированы и их поведение стандартизировано в pepeunit
        - Идёт сохранение стандартизированного состояния, обновляются состояния обновлений и тд.
        - Выполняется одним потоком Uvicorn
        - Для топика state сохранение идёт в Postgres
        - Для топика log сохранение идёт в Clickhouse и обновляется время в Postgres
    - example.com/+/pepeunit - принадлежащие Unit
        - Прямое сохранение всего что выдают Unit, в виде текста в Postgres
        - В бд сохраняется только 1 запрос за N секунд по умолчанию 30
3. Общий лимит на обьём информации передаваемой в payload топика берётся из настроек
4. Выполняется одним потоком Uvicorn. Практический потолок 4к запросов в секунду

### Проектное состояние
1. Авторизация топиков остаётся без изменений
2. example.com/+/+/+/pepeunit остаётся в python, разрешаем сохранять не чаще чем лимит backend_state_send_interval - 1 сек
3. example.com/+/pepeunit переходит в go приложение
    - Go приложение поддерживает одно клиентское соединение и подписано на все топики вида example.com/+/pepeunit
    - Обрабатывает запросы согласно политикам, которые постоянно синхронизируется с python бекендом
4. Связка python + go должна иметь следующие политики накопления данных:
    - По умолчанию все политики выключенны и агрегация и/или хранение не идёт, такие топики скипаются всегда. Пользователь должен сам своими руками включить одину из политик, потому что в будущем это повлияет на его бабки.
    - Хранение последнего значения
        - Postgres
        - Сохранение 1 сообщения в N сек/минут/часов
        - Например: отлеживать последнее состояние датчика, часто этого достаточно
    - Хранение N последних записей
        - Clickhouse
        - Для ивентовых событий
        - Например: cработка сигнализации или датчика движения
    - Хранение N записей за последние 0-N минут/часов
        - Clickhouse
        - Хранятся все записи в диапазоне от текущего момента до 0-N минут/часов назад
        - C указанием буферизации от 1 минуты до N часов, чтобы не дудосить clickhouse запросами каждую секунду
        - Нужно в местах где нужно 100% разрешение по времени и не нужна агрегация, для сырых данных и внешней аналитики. При этом платить деньги за долговременное хранение всех значений не хочется
        - Например: точный температурный эксперимент в муфельной печи - задача узнать точную кривую для выведения коэффициентов
    - Хранение изображений с накоплением в видео
        - Minio + Clickhouse
        - Сырые изображения приводятся к заданному формату
        - Изображения накапливаются по их общему размеру, числу или времени
        - Изображения мержатся в видео
        - Видео загружется в minio
        - Например: таймлапсы через esp32 cam
    - Хранение файла
        - Minio + Сlickhouse or postgres
        - Аналогично: Хранение последнего значения, Хранение N последних записей, Хранение N записей за последние 0-N минут/часов
        - Возможность сжатия tgz, tar, zip. Для tgz надо настроить обязательно level и wbits
        - Для изображений возможность обрезки и сжатия
        - Добавляется лимитация по объёму
        - Загрузка в minio
        - Напирмер: одиночные изображения, csv с данными
    - Агрегация. С заданной шириной окна агрегации 0-N часов/минут в Clickhouse. Для графиков температур или технических метрик
        - Clickhouse
        - Привязка должна идти к целым часам. 00:00-00:05 для 5 минут или 00:00-01:00 для 1 часа
        - Идёт буферизация за указанное время, до следующего времени после чего происходит вычисление с сохранением в clickhouse:
            - min/max
            - sum
            - avg
        - Например: датчики температуры, нет смысла хранить с разрешением 10 сек, достаточно среднего значения за час или 15 минут
5. Для каждой политики можно задать время действия:
    - от какой-то даты и в дальнейшем постоянными
    - от текущей даты до заданного значения
    - Диапазон времени по датам с часами и минутами
    - Постоянно
5. На стороне python должна быть возможность получать данные от разных типов агрегации через запросы в Clickhouse с разными пагинациями
6. Таблицы clickhose думаю лучше сделать отдельными для каждого рода политики, чтобы агрегационные запросы были эффективнее
7. Везде нужно хранить размер содержимого, чтобы знать общий вес хранения. Он будет влиять на монетизацию в дальнейшем.

### Поддерживаемые политики для разных типов данных:

Типы данных:
1. Числовые int, float:
    - Хранение последнего значения
    - Хранение N последних записей
    - Хранение N записей за последние 0-N минут/часов
    - Агрегация
2. Строки без структуры:
    - Хранение последнего значения
    - Хранение N последних записей
    - Хранение N записей за последние 0-N минут/часов
    - Агрегация
3. Сериализуемый JSON в виде строки:
    - Хранение последнего значения
    - Хранение N последних записей
    - Агрегация
4. Изображения:
    - Хранение изображений с накоплением в видео
    - Хранение файла
5. Бинарные данные:
    - Хранение файла

### Ожидания

- Воркер Go, берёт на себя задачу обработки потоков данных и их складирование в хранилища
- Бекенд на Python, берёт на себя работу с юзерами, отдачу им всех накопленных данных
- Grafana в будущем позволяет всё это отображать

## Публичные Repo из github и gitlab
Создаётся repository_regestry:
- uuid
- тип внешнего источника
- ссылка на источник - unique
- время создания
- статус синхронизации
- текст ошибки
- время последней синхронизации
- размер дирректории

1. Все публичные репозитории мигрируют из Repo в repository_regestry
1. Придумать систему обновления по доменам. Процесс обновления должен уметь не дудосить репозитории, а постепенно методично обновляться.
1. Нужна настройка параллельности и лимитирования числа запросов в еденицу времени
1. Данные в repository_regestry обновляются каждые N часов через эту систему, с возможностью полного отключения этой функции
1. Админ может принудительно заставить обновиться, процесс будет как при автоматическом. Но нужно дать возможность админу обновлять конкретные домены.
1. Приватные репозитории админ обновлять не может
1. Пользователь может нажать обновление у подконтрольного репозитория

Приватные:

Всё остаётся как раньше, они хранятся в единичном экземпляре для каждого repo отдельно и не попадают в repository_regestry

Публичные:

Хранятся на инстансе физически в единственном экземпляре
- нужно проверить можно ли читать файлы множество раз через gitpython, от этого будет зависеть реализация, копирование или подмена uuid

### Ожидаение

1. У Repo будет плашка последнего обновления, его статуса и ошибки. Для публичных repository_regestry, для приватных эти поля появятся в repo
2. Кнопка создания репозитория будет подменена, на кнопку поиска существующих репозиториев
1. Появится ручка отдающая существующие публичные репозитории, с сортировками:
    - по числу unit
    - числу repo
    - датам
    - размеру
    - типу внешнего источника
    - статусу обновления
    - времени синхронизации - важно для админа
    - времени создания
    - поиск по description и name
3. Хорошо бы парсить Description и некоторые базовые поля из readme.md для улучшенного поиска по публичным репозиториям
4. Фикс проблемы github в интеграционных тестах
5. Обновлены сами Интеграционные тесты

## Анализ динамического состояния узла

1. Анализ общего числа сообщений поступающих на бэкенд
    - mqtt
    - gql
    - rest
    - aiogram
1. Трекер занятых ресурсов - cpu, ram
1. Оставшееся место
1. Аптайм
1. Трекер ошибок, какие возникают чаще, а какие реже
1. Трекер алерт крашей, с дросселированием - в телегу админу, надо запоминать сколько раз возник

## Анализ нагрузки

На эти метрики будет опираться монетизация и настройки пользователей

1. Система отслеживания нагрузки на топики Unit - Расчёт желательно на стороне EMQX
1. Система отслеживания средней нагрузки на один Unit - Метрика загрузки для repo
1. Метрикой должен быть MPS - запросы в секунду
1. Нужна автоматическая отсечка, если Unit превысил лимиты

## Алерты 
1. Нужно установить начиная с какого уровня лога, будет отправляться alert
1. Дросселирование в телеграм должно работать через Backend, а значит нужна пременная, регламентирующая расстояние между алертами в телеге
1. EMQX должен пересылать алерты на определённый тип ошибок, на основе Rule Engine

## Система бордов

1. Интеграция с Графана, с возможностью авторизовываться через существующий аккаунт
1. Нужны базовые борды для админа - динамическое состояние, анализ нагрузки, трекинг ошибок
1. Нужна возможность конфижить борды с фронта, по пользовательским инициативам, этот функционал должен быть продублирован хотябы частично в телегу

## Монетизация для держателей инстансов

1. Подключаемая монетизация на основе Telegram и криптовалют
1. Основана должна быть на нагрузке от Unit, который создаёт юзер
1. Возможность настройки монетизации для администратора
1. Агригируещие топики должны быть монетизированы с другой политикой, т.к. они несут накладные расходы на хранение данных

## Система грейдов инстансов

1. Добавить итеративность в проверку нагрузки
1. Добавить хэш в отчёт, чтобы было сложнее его поменять
1. Отчёт по нагрузке должен предоставляться по спец запросу load_limit
1. Число бесплатных MPS
1. Стоймость MPS всверх бесплатных
1. Число бесплатных топиков с агрегацией (нужно придумать метрику)
1. Стоймость за один топик с агрегацией (нужно придумать метрику)
1. Токен доступа для скрапера генерит Админ инстанса

## Федерация

TODO: требуется крепкая проработка

1. Федеративный хаб Repo, c поиском по Unit на мультиинстансе
1. Внедрение activity pub
1. Система взаимодействия между инстансами
1. Проработать activity pub
1. Проработать bridge y emqx, до разных инстансов
1. Белые и чёрные листы доменов для создания repo
1. Импорт экспорт всех данных учётной записи по запросу Пользователя
1. Добавить кнопку обновления env от pepeunit, для будущей возможности переноса Unit на другие инстансы
1. Проработать условия автоматического бана внешних инстансов
1. Нужен бан топиков от внешних инстансов, по условиям (выдумать условия)

## Видео для документации
1. Нужно видео по развёртыванию Pepeunit
1. Нужно видео где с 0 на уже развёрнутом инстансе, создаётся готовая система по существующим Repo - от лица Пользователя
1. Нужно видео где с 0 на уже развёрнутом инстансе, разработчик Unit последовательно создёт новый Unit с 0 - от лица разработчика Unit