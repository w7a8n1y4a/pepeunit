# Дорожная карта для Pepeunit

## 0.7.0 Система агрегации данных

Сейчас:
1. Авторизация для подписки и публикации в топики идёт через python, это делеатеся через rest, с хорошей производительностью
2. Есть 2 вида топиков
    - системные имеют 5 элементов в названии, там заложено очень много бизнесовой логики, и вынести возможность в целом нет этот функционал куда-либо. Выполняется одним потоком Uvicorn
    - unit топики имеют 3 элемента в названии, это то что генерят Unit, сохранение идёт в базу, но не чаще чем 30 сек на топик. Выполняется одним потоком Uvicorn
3. Работа идёт только с Postgres в этом сегменте. Есть команда Log, она умеет работать с clickhouse

Идём к:
1. Авторизацию топиков доверяем python
2. Системные топики доверяем python в одном потоке, но разрешаем отправлять запросы не чаще чем N секунд. Это значительно упростит логику go приложения
3. Go приложение выступает как агрегатор, его задача подписыватья на топики, на которые прикажет python, агрегировать, сохранять и тд в postgres и clickhouse
4. Есть два основных сценария:
    - Подписка на все unit топики имеющие 3 элемента в названии. Это может быть в целом один mqtt клиент у которого динамически обновляются подписка.
        
        Сохранение здесь нужно, если пользователь зайдёт в UnitNode, он должен увидеть что время последнего сообщения было не очень давно + увидеть само сообщение

    - Собственно сама агрегация, тут суть что поглощаются вообще все данные которые приходят в топик обрабатываются и результаты записываются в clickhouse. Пользователь может через бекенд для отдельного топика, настроить разного рода агрегации.
        - Хранить последние N записей
        - Задать окно и увидеть вместо сообщений каждые N сек среднее за N часов
        - Время агрегации постоянное или временное

Дать Пользователю создавать временного слушателя mqtt топиков, в идеале внешний сервис на go, а на бек добавить обратную очередь на сохранение:
1. Он бы подписывался на все или часть топиков пользователя
    - на определённое время
    - c ограничением по объёму сохраняемой информации
1. Нужно несколько типов слушателей:
    - долговременные
    - агрегационные со смещающимся окном
    - подумать о возможности динамического размера окна
1. Стратегии сохранения
    - хранятся только данные уже рассчитанные
    - cохранение данных в телегу
    - clickhouse
1. Система собираемых бордов с данными для Graphana и TG интеграции

## Анализ динамического состояния узла

1. Анализ общего числа сообщений поступающих на бэкенд
    - mqtt
    - gql
    - rest
    - aiogram
1. Трекер занятых ресурсов - cpu, ram
1. Оставшееся место
1. Аптайм
1. Трекер ошибок, какие возникают чаще, а какие реже
1. Трекер алерт крашей, с дросселированием - в телегу админу, надо запоминать сколько раз возник

## Анализ нагрузки

На эти метрики будет опираться монетизация и настройки пользователей

1. Система отслеживания нагрузки на топики Unit - Расчёт желательно на стороне EMQX
1. Система отслеживания средней нагрузки на один Unit - Метрика загрузки для repo
1. Метрикой должен быть MPS - запросы в секунду
1. Нужна автоматическая отсечка, если Unit превысил лимиты

## Алерты 
1. Нужно установить начиная с какого уровня лога, будет отправляться alert
1. Дросселирование в телеграм должно работать через Backend, а значит нужна пременная, регламентирующая расстояние между алертами в телеге
1. EMQX должен пересылать алерты на определённый тип ошибок, на основе Rule Engine

## Система бордов

1. Интеграция с Графана, с возможностью авторизовываться через существующий аккаунт
1. Нужны базовые борды для админа - динамическое состояние, анализ нагрузки, трекинг ошибок
1. Нужна возможность конфижить борды с фронта, по пользовательским инициативам, этот функционал должен быть продублирован хотябы частично в телегу

## Монетизация для держателей инстансов

1. Подключаемая монетизация на основе Telegram и криптовалют
1. Основана должна быть на нагрузке от Unit, который создаёт юзер
1. Возможность настройки монетизации для администратора
1. Агригируещие топики должны быть монетизированы с другой политикой, т.к. они несут накладные расходы на хранение данных

## Система грейдов инстансов

1. Добавить итеративность в проверку нагрузки
1. Добавить хэш в отчёт, чтобы было сложнее его поменять
1. Отчёт по нагрузке должен предоставляться по спец запросу load_limit
1. Число бесплатных MPS
1. Стоймость MPS всверх бесплатных
1. Число бесплатных топиков с агрегацией (нужно придумать метрику)
1. Стоймость за один топик с агрегацией (нужно придумать метрику)
1. Токен доступа для скрапера генерит Админ инстанса

## Федерация

TODO: требуется крепкая проработка

1. Федеративный хаб Repo, c поиском по Unit на мультиинстансе
1. Внедрение activity pub
1. Система взаимодействия между инстансами
1. Проработать activity pub
1. Проработать bridge y emqx, до разных инстансов
1. Белые и чёрные листы доменов для создания repo
1. Импорт экспорт всех данных учётной записи по запросу Пользователя
1. Добавить кнопку обновления env от pepeunit, для будущей возможности переноса Unit на другие инстансы
1. Проработать условия автоматического бана внешних инстансов
1. Нужен бан топиков от внешних инстансов, по условиям (выдумать условия)

## Видео для документации
1. Нужно видео по развёртыванию Pepeunit
1. Нужно видео где с 0 на уже развёрнутом инстансе, создаётся готовая система по существующим Repo - от лица Пользователя
1. Нужно видео где с 0 на уже развёрнутом инстансе, разработчик Unit последовательно создёт новый Unit с 0 - от лица разработчика Unit