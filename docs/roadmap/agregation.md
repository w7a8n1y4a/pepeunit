# Конвейеры данных

## Задача

Имеется 10000 Unit устройств IoT, они могут предельно отправлять по 30 запросов в секунду в emqx. Для некоторых из них ~700-1000, пользователи захотят увидеть данные и графики, следовательно их нужно обрабатывать и хранить. Т.е. пиковая нагрузка может составить ~ 30000 сообщений в секунду.

Никакого адекватного размера flash памяти, ram и cpu нехватит чтобы хранить и обрабатывать такие большие данные. Поэтому для уменьшения нагрузки и уменьшения размера инфраструктуры нужно разработать систему, которая бы представляла из себя конвейерную воронку данных. Задача этого конвейера используя различные агрегации и тд, отсеивать и сжимать данные, для уменьшения хранимого объёма и ресурса clickhouse и postgres.

## Текущее состояние системы
1. Авторизация для подписки и публикации в топики идёт через python, это делается через rest, с хорошей производительностью
    - рест автоматически раскидывается на отдельные воркеры
    - у emqx брокера есть кеширование для авторизаций
2. Есть 2 вида топиков
    - example.com/+/+/+/pepeunit - системные, они забронированы и их поведение стандартизировано в pepeunit
        - Идёт сохранение стандартизированного состояния, обновляются состояния обновлений и тд.
        - Выполняется одним потоком Uvicorn
        - Для топика state сохранение идёт в Postgres
        - Для топика log сохранение идёт в Clickhouse и обновляется время в Postgres
    - example.com/+/pepeunit - принадлежащие Unit
        - Прямое сохранение всего что выдают Unit, в виде текста в Postgres
        - В бд сохраняется только 1 запрос за N секунд по умолчанию 30
3. Общий лимит на обьём информации передаваемой в payload топика берётся из настроек
4. Выполняется одним потоком Uvicorn. Практический потолок 4к запросов в секунду

## Проектное состояние
1. Авторизация топиков остаётся без изменений
1. example.com/+/+/+/pepeunit остаётся в python
    - Разрешаем сохранять не чаще чем лимит backend_state_send_interval
1. example.com/+/pepeunit больше не будет существовать в python, а в go приложении формат подписки изменится
    - Go приложение будет поддерживать 1 клиенстское соединение и подписываться на список, синхронизируемый из python приложения и postgres таблицы. Список топиков будет вида example.com/bcc4d500-5417-4ecd-b1f8-436964709fea, example.com/08a14461-c5be-4793-ab7a-4b545dcc1cf5 и т.д., это важно, чтобы не перегружать систему, т.к. 99% топиков вида example.com/+ не потребуют обработки.
    - Обрабатывает запросы согласно настроенным конвейерам
    - Настройки обработки для каждого топика - синхронизируется с python бэкендом
1. Конвейеры данных имеют следующие этапы:
    - Время действия
    - Фильтрация
    - Преобразование
    - Одна из политик накопления
    - Сохранение
1. После работы go приложения в системе есть обогащённые данные
1. Конвейер должно быть можно сохранять в yml, чтобы создатели Unit могли оставлять их в репозиториях
1. На стороне python должна быть возможность получать эти обогащённые данные в зависимости от их типа и настроек конвейера
1. Должна быть возможность экспорта данных для конкретных топиков
1. Таблицы clickhose сделать отдельными для каждого рода политики, чтобы запросы были эффективнее

## Время действия конвейера

1. от какой-то даты и в дальнейшем постоянными
2. от текущей даты до заданного значения
3. Диапазон времени по датам с часами и минутами
4. Постоянно

## Фильтрация
1. По типу входного значения
    - Числа
    - Текст
1. Белые списки значений
    - списки значений
1. Чёрные списки значений
    - списки значений - null, None, float('NaN'), float('inf')
1. Минимальный порог значений
    - одно число
1. Максимальный порог значений
    - одно числа
1. Диапазон значений
    - два числа
1. Максимальная частота обновлений
    - N сек/минут/часов
1. Уникальность
    - проверка предидущего значения по хэшу payload
1. Размер
    - верхний порог размера в байтах/символах

## Преобразование
1. Числа
  - Округление
  - Домножение на коэффициент
  - Расчёт по формуле (Функционал после 1.0.0 через go expr, должен быть расчёт времени вычисления и проверка валидности выражения)
1. Текст
  - slice

## Политики обработки

### Хранение последнего значения

Как работает:

1. Получает значения из топика
1. Значение обновляется не чаще чем backend_state_send_interval игнорируя фильтры
1. Записывает значение в postgres, через пакетную буферную очередь для всего инстанса, буфер длинной 5-10s

Поля бд postgres, units_nodes:
- state - text
- state_type enum Number или Text

Например:

Последнее состояние - последнее состояние датчика

### Хранение N последних записей

Как работает:

1. Получает значение из топика
1. Записывает строку в Clickhouse, через пакетную буферную очередь, буфер длинной 5-10s
1. За поддержание корректного числа отвечает система отчистки


Поля бд clickhouse, n_last_entry:
- uuid
- unit_node_uuid
- state
- state_type
- create_datatime
- max_count
- size

Отчистка:
1. Отдельный процесс чистит записи спец запросом, каждую минуту

Запросы которые должны выполнятся:

1. Создание записей, сразу по 1-1000 шт за 1 запрос. Каждое значение должно быть сохранено. Каждая запись должна быть создана с уникальным uuid
2. Запросы удаления должны для каждого unit_node_uuid делать сортировку по create_datetime и присваивать им инкремент. От 1 до N числа записей. Если N будет больше max_count то записи надо удалить. count_records задаётся для каждого unit_node_uuid отдельно и записывается в max_count
3. Выборки по unit_node_uuid с сортировкой по create_datatime, дополнительно поиск по включению в state (подобие %ilike%)

Например:

Ивентовые события - cработка сигнализации или датчика движения
    
### Хранение временного окна

Как работает:

1. Получает значение из топика
1. Записывает строку в Clickhouse, через пакетную буферную очередь, буфер длинной 5-10s
1. За поддержание окна отвечает expiration_datetime и ttl механизм

Поля бд clickhouse, window_entry:
- uuid
- unit_node_uuid
- state
- state_type
- create_datatime
- expiration_datetime
- size

Запросы которые должны выполнятся:
1. Создание записей, сразу по 1-1000 шт за 1 запрос. Каждое значение должно быть сохранено. Каждая запись должна быть создана с уникальным uuid
2. Удаление должно быть автоматизировано через ttl и expiration_datetime
3. Выборки по unit_node_uuid с сортировкой по create_datatime, дополнительно поиск по включению в state (подобие %ilike%)

Например:

Когда нужно 100% разрешение по времени - узнать точную кривую муфельной печи для выведения коэффициентов

### Агрегация

Как работает:

1. Получает значение из топика
1. Отправляет значение в нужную очередь внутри go
1. Очередь копит и производит расчёт в заранее известное время внутри go
1. Записывает агрегированное значение в Clickhouse

Поля бд clickhouse, aggregation_entry:
- uuid
- unit_node_uuid
- state - float
- aggregation_type - avg,min,max,sum
- create_datatime
- start_window_datetime - обозначает начало окна агрегации
- end_window_datetime - обозначает конец окна агрегации

Запросы которые должны выполнятся:
1. Создание записей, на инстанс через буфер может быть порядка 3000 записей за 1 insert, т.к. расчёты будут произведены почти одновременно
2. Удаление не подразумевается, т.к. объём данных достаточно мал
3. Выборки по unit_node_uuid с сортировкой по create_datatime и выборкой по временному диапазону на основе поля start_window_datetime

Например:

Cоздание ровных временных рядов с заданным разрешением - датчики температуры, влажности и давления

## Сохранение
- скрытый от пользователя этап

1. Расчитывает размер сохраняемых данных
1. Сохраняет данные согласно их типу и политике хранения

## Пример yml

```yml
version: 1.0

pipeline:
  active_period:
    type: "date_range"  # permanent/from_date/to_date/date_range
    start: 2023-11-15T00:00:00Z
    end: 2024-11-15T00:00:00Z

  filters:
    type_input_value: "number" # number/text
    type_value_filtering: "whitelist" # null/whitelist/blacklist
        values: [1,2,3,4,5]
    type_value_threshold: "range" # null/min/max/range
        min: -40
        max: 120
    max_rate: "10s" # Ns/Nm/Nh
    last_unique_check: false
    max_size: 10 # in symbols

  transformations:
    - type: "numeric"
      multiplication: true
        coefficient: 0.3
      round: true
        decimal_point: 3
    - type: "text"
      slice:
        start: -4
        end: -1

  processing_policy:
    - type: "last_value"
    - type: "n_records"
      count_records: 1024  # 1-8192
    - type: "time_window"
      relative:
        window_size: "1h" # 1m, 5m, 1h, 12h
    - type: "aggregation"
      window_size: "1h"  # 1m, 5m, 1h, 12h
      aggregation_functions: "avg" # avg/min/max/sum

```

## Ожидания

- Система может накапливать обогащённые данные
- Система может предоставлять эти данные пользователям
