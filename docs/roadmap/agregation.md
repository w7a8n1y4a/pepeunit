# Конвейеры данных

## Задача

Имеется 10000 Unit устройств IoT, они отправляют по 30 запросов в секунду в emqx. Для некоторых из них ~1000, пользователи захотят увидеть данные и графики.

При нагрузке в 30000 сообщений в секунду не обойтись без разного рода фильтраций данных и их сжатия любыми способами. Обновление системы должно предоставить пользователям возможность видеть свои данные. Т.к. устройства координально отличаются, структура хранения данных также должна отличаться в зависимости от способа обработки, для поддержания работы бизнеслогики.

## Текущее состояние системы
1. Авторизация для подписки и публикации в топики идёт через python, это делается через rest, с хорошей производительностью
    - рест автоматически раскидывается на отдельные воркеры
    - у emqx брокера есть кеширование для авторизаций
2. Есть 2 вида топиков
    - example.com/+/+/+/pepeunit - системные, они забронированы и их поведение стандартизировано в pepeunit
        - Идёт сохранение стандартизированного состояния, обновляются состояния обновлений и тд.
        - Выполняется одним потоком Uvicorn
        - Для топика state сохранение идёт в Postgres
        - Для топика log сохранение идёт в Clickhouse и обновляется время в Postgres
    - example.com/+/pepeunit - принадлежащие Unit
        - Прямое сохранение всего что выдают Unit, в виде текста в Postgres
        - В бд сохраняется только 1 запрос за N секунд по умолчанию 30
3. Общий лимит на обьём информации передаваемой в payload топика берётся из настроек
4. Выполняется одним потоком Uvicorn. Практический потолок 4к запросов в секунду

## Проектное состояние
1. Авторизация топиков остаётся без изменений
1. example.com/+/+/+/pepeunit остаётся в python
    - Разрешаем сохранять не чаще чем лимит backend_state_send_interval - 1 сек. 
    - Попробовать добавить лимит на паттерн в emqx
1. example.com/+/pepeunit больше не будет существовать в python, а в go приложении формат подписки изменится
    - Go приложение будет поддерживать 1 клиенстское соединение и подписываться на список, синхронизируемый из python приложения и postgres таблицы. Список топиков будет вида example.com/bcc4d500-5417-4ecd-b1f8-436964709fea, example.com/08a14461-c5be-4793-ab7a-4b545dcc1cf5 и т.д., это важно, чтобы не перегружать систему, т.к. 99% топиков вида example.com/+ не потребуют обработки.
    - Обрабатывает запросы согласно настроенным конвейерам
    - Настройки обработки для каждого топика - синхронизируется с python бэкендом
1. Конвейеры данных имеют следующие этапы:
    - Время действия
    - Фильтрация
    - Преобразование
    - Одна из политик накопления
    - Сохранение
1. После работы go приложения в системе есть обогащённые данные
1. Конвейер должно быть можно сохранять в yml, чтобы создатели Unit могли оставлять их в репозиториях
1. На стороне python должна быть возможность получать эти обогащённые данные в зависимости от их типа и настроек конвейера
1. Должна быть возможность экспорта данных для конкретных топиков
1. Таблицы clickhose сделать отдельными для каждого рода политики, чтобы запросы были эффективнее

## Время действия 

1. от какой-то даты и в дальнейшем постоянными
2. от текущей даты до заданного значения
3. Диапазон времени по датам с часами и минутами
4. Постоянно

## Фильтрация
1. По типу входного значения
    - Числа
    - Текст
    - Изображения
    - Файлы
1. Белые списки значений
    - списки значений
1. Чёрные списки значений
    - списки значений - null, None, float('NaN'), float('inf')
1. Минимальный порог значений
    - одно число
1. Максимальный порог значений
    - два числа
1. Диапазон значений
    - два числа
1. Максимальная частота обновлений
    - N сек/минут/часов
1. Уникальность
    - проверка предидущего значения по хэшу payload
1. Размер
    - верхний порог размера в байтах/символах

## Преобразование
1. Числа
    - Округление
    - Домножение на коэффициент
    - Расчёт по формуле (Функционал после 1.0.0 через go expr, должен быть расчёт времени вычисления и проверка валидности выражения)
1. Изображение
    - Изменение размера
    - Изменение плотности пикселей
    - Обрезка
    - Конвертация формата изображения
1. Файлы
    - Сжатие Tgz (wbits + level), Tar, Zip

## Политики обработки

### Хранение последнего значения

Как работает:

1. Получает значения из топика
1. Сохраняет файл в minio если тип соответствует
1. Записывает значение в postgres

Буферизация:

Накапливает все записи для инстанса за хотябы 1м - нужно чтобы не дудосить БД лишними транзакциями, реализация на основе очереди

Отчистка:
1. Отдельный воркер проверяет, какие записи есть в postgres, и чистит минио оставляя только имеющиеся

Поля бд postgres, units_nodes:
- state текст, содержит запись или имя файла
- state_type, содержит тип для state из enum

Хранение по типам:
- Числа - Postgres
- Текст - Postgres
- Изображения - Postgres + Minio
- Файлы - Postgres + Minio

Например:

Последнее состояние - последнее состояние датчика

### Хранение N последних записей

Как работает:

1. Получает значение из топика
1. Сохраняет файл в minio если тип соответствует
1. Записывает строку в Clickhouse, за поддержание N записей, отвечает процесс отчистки

Буферизация:

Накапливает все записи для инстанса за хотябы 1м - нужно чтобы не дудосить БД лишними транзакциями, реализация на основе очереди

Отчистка:
1. Отдельный процесс чистит записи спец запросом, каждую Минуту, для файлов ставится флаг is_deleted == true
1. Ещё один процесс удаляет файлы, по флагу is_deleted == true, он единый для всех таблиц

Поля бд clickhouse, n_last_entry:
- uuid
- unit_node_uuid
- state
- state_type
- create_datatime
- is_deleted
- size

Хранение по типам:
- Числа - Clickhouse
- Текст - Clickhouse
- Изображения - Clickhouse + Minio
- Файлы - Clickhouse + Minio

Например:

Ивентовые события - cработка сигнализации или датчика движения
    
### Хранение временного окна

Как работает:

1. Получает значение из топика
1. Отбирает значения
  - Absolyte - записываются только те которые попадают в диапазон
  - Relative - пишет все записи
1. Сохраняет файл в minio если тип соответствует
1. Записывает строку в Clickhouse
  - за поддержание окна в Absolyte отвечает go приложение
  - за поддержание окна в Relative отвечает система отчистки аналогичная хранению N записей

Буферизация:

Накапливает все записи для инстанса за хотябы 1м - нужно чтобы не дудосить БД лишними транзакциями, реализация на основе очереди

Поля бд clickhouse, window_entry:
- uuid
- unit_node_uuid
- state
- state_type
- create_datatime
- aggregation_type - enum Absolyte Relative
- is_deleted - отвечает за удаление файлов
- size

Отчистка:
1. Отдельный процесс чистит записи спец запросом, каждую Минуту, для файлов ставится флаг is_deleted == true
1. Ещё один процесс удаляет файлы, по флагу is_deleted == true, он единый для всех таблиц

Хранение по типам:
- Числа - Clickhouse
- Текст - Clickhouse
- Изображения - Clickhouse + Minio
- Файлы - Clickhouse + Minio

Например:

Когда нужно 100% разрешение по времени - узнать точную кривую муфельной печи для выведения коэффициентов
Когда нужно видеть данные за последние 24ч 

### Агрегация

Как работает:

1. Получает значение из топика
1. Отправляет значение в нужную очередь
1. Очередь копит и в нужный момент производит расчёт, заранее известное время
1. Записывает строку в Clickhouse

Поля бд clickhouse, aggregation_entry:
- uuid
- unit_node_uuid
- state - float
- create_datatime
- start_window_datetime
- end_window_datetime
- size

Хранение по типам:
- Числа - Clickhouse

Отчистка:
1. Нет

Например:

Cоздание ровных временных рядов с заданным разрешением - датчики температуры, влажности и давления

## Сохранение
- скрытый от пользователя этап

1. Расчитывает размер сохраняемых данных
1. Сохраняет данные согласно их типу и политике хранения

## Пример yml

```yml
version: 1.0

pipeline:
  active_period:
    type: "date_range"  # permanent/from_date/to_date/date_range
    start: 2023-11-15T00:00:00Z
    end: 2024-11-15T00:00:00Z

  filters:
    type_input_value: "number" # number/text/image/binary
    type_value_filtering: "whitelist" # null/whitelist/blacklist
        values: [1,2,3,4,5]
    type_value_threshold: "range" # null/min/max/range
        min: -40
        max: 120
    max_rate: "10s" # Ns/Nm/Nh
    last_unique_check: false
    max_size: 10 # in symbols

  transformations:
    - type: "numeric"  # numeric/image/file
      multiplication: true
        coefficient: 0.3
      round: true
        decimal_point: 3
    - type: "image"  # numeric/image/file
      resize: true
        width: 640
        hight: 320
      pixel_density: true
        dpi: 300
      clipping: true
        x: 50
        y: 50
        width: 240
        hight: 120
      format: "jpg" # null/png/jpg/svg/webp
    - type: "file"  # numeric/image/file
      compression: tgz # null/tgz/tar/zip
        wbits: 0
        level: 15

  processing_policy:
    - type: "last_value"
      file_ttl: 86400
    - type: "n_records"
      count_records: 1024  # 1-8192
    - type: "time_window"
      absolyte:
        start: 2023-11-15T00:00:00Z
        end: 2024-11-15T00:00:00Z
      relative:
        window_size: "1h" # 1m, 5m, 1h, 12h
      save_interval: 0 # in second
    - type: "aggregation"
      window_size: "1h"  # 1m, 5m, 1h, 12h
      aggregation_functions: "avg" # avg/min/max/sum

```

## Ожидания

- Система может накапливать обогащённые данные
- Система может предоставлять эти данные пользователям
