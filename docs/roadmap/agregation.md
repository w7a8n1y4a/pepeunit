# Конвейеры данных

## Текущее состояние системы
1. Авторизация для подписки и публикации в топики идёт через python, это делается через rest, с хорошей производительностью
    - рест автоматически раскидывается на отдельные воркеры
    - у emqx брокера есть кеширование для авторизаций
2. Есть 2 вида топиков
    - example.com/+/+/+/pepeunit - системные, они забронированы и их поведение стандартизировано в pepeunit
        - Идёт сохранение стандартизированного состояния, обновляются состояния обновлений и тд.
        - Выполняется одним потоком Uvicorn
        - Для топика state сохранение идёт в Postgres
        - Для топика log сохранение идёт в Clickhouse и обновляется время в Postgres
    - example.com/+/pepeunit - принадлежащие Unit
        - Прямое сохранение всего что выдают Unit, в виде текста в Postgres
        - В бд сохраняется только 1 запрос за N секунд по умолчанию 30
3. Общий лимит на обьём информации передаваемой в payload топика берётся из настроек
4. Выполняется одним потоком Uvicorn. Практический потолок 4к запросов в секунду

## Проектное состояние
1. Авторизация топиков остаётся без изменений
1. example.com/+/+/+/pepeunit остаётся в python
    - Разрешаем сохранять не чаще чем лимит backend_state_send_interval - 1 сек. 
    - Попробовать добавить лимит на паттерн в emqx
1. example.com/+/pepeunit больше не будет существовать в python, а в go приложении формат подписки изменится
    - Go приложение будет поддерживать 1 клиенстское соединение и подписываться на список, синхронизируемый из python приложения и postgres таблицы. Список топиков будет вида example.com/bcc4d500-5417-4ecd-b1f8-436964709fea, example.com/08a14461-c5be-4793-ab7a-4b545dcc1cf5 и т.д., это важно, чтобы не перегружать систему, т.к. 99% топиков вида example.com/+ не потребуют обработки.
    - Обрабатывает запросы согласно настроенным конвейерам
    - Настройки обработки для каждого топика - синхронизируется с python бэкендом
1. Конвейеры данных имеют следующие этапы:
    - Время действия
    - Фильтрация
    - Преобразование
    - Одна из политик накопления
    - Буферизация
    - Сохранение
1. После работы go приложения в системе есть обогащённые данные
1. Конвейер должно быть можно сохранять в yml, чтобы создатели Unit могли оставлять их в репозиториях
1. На стороне python должна быть возможность получать эти обогащённые данные в зависимости от их типа и настроек конвейера
1. Должна быть возможность экспорта данных для конкретных топиков
1. Таблицы clickhose сделать отдельными для каждого рода политики, чтобы запросы были эффективнее

## Время действия 

1. от какой-то даты и в дальнейшем постоянными
2. от текущей даты до заданного значения
3. Диапазон времени по датам с часами и минутами
4. Постоянно

## Фильтрация
1. По типу входного значения
    - Числа
    - Текст
    - Изображения
    - Файлы
1. Белые списки значений
    - списки значений
1. Чёрные списки значений
    - списки значений - null, None, float('NaN'), float('inf')
1. Минимальный порог значений
    - одно число
1. Максимальный порог значений
    - два числа
1. Диапазон значений
    - два числа
1. Максимальная частота обновлений
    - N сек/минут/часов
1. Уникальность
    - проверка предидущего значения по хэшу payload
1. Размер
    - верхний порог размера в байтах/символах

## Преобразование
1. Числа
    - Округление
    - Домножение на коэффициент
    - Расчёт по формуле (Функционал после 1.0.0 через go expr, должен быть расчёт времени вычисления и проверка валидности выражения)
1. Изображение
    - Изменение размера
    - Изменение плотности пикселей
    - Обрезка
    - Конвертация формата изображения
1. Файлы
    - Сжатие Tgz (wbits + level), Tar, Zip

## Политики обработки

### Хранение последнего значения

Как работает:

1. Получает значения из топика
1. Строго проверяет, чтобы с момента прошлой записи прошло не менее backend_state_send_interval для данного топика
1. Сохраняет файл в minio если тип соответствует
1. Накапливает все записи для инстанса за хотябы 30с - нужно чтобы не дудосить postgres лишними транзакциями
1. Записывает значение в postgres

Отчистка:
1. Отдельный воркер проверяет, какие записи есть в postgres, и чистит минио оставляя только имеющиеся

Поля бд postgres, units_nodes:
- state текст, содержит запись или имя файла
- state_type, содержит тип для state из enum

Хранение по типам:
- Числа - Postgres
- Текст - Postgres
- Изображения - Postgres + Minio
- Файлы - Postgres + Minio

Например:

Последнее состояние - последнее состояние датчика

### Хранение N последних записей

Как работает:

1. Получает значение из топика
1. Сохраняет файл в minio если тип соответствует
1. Записывает строку в Clickhouse

Отчистка:
1. Отдельный процесс чистит записи спец запросом, каждую Минуту, для файлов ставится флаг is_deleted == true
1. Ещё один процесс удаляет файлы, по флагу is_deleted == true, он единый для всех таблиц

Поля бд clickhouse:
- inc возможно не нужное поле
- uuid
- unit_uuid
- state
- state_type
- create_datatime
- is_deleted

Хранение по типам:
- Числа - Clickhouse
- Текст - Clickhouse
- Изображения - Clickhouse + Minio
- Файлы - Clickhouse + Minio

Например:

Ивентовые события - cработка сигнализации или датчика движения
    
### Хранение временного окна

Как работает:

1. Получает значение из топика
1. Сохраняет файл в minio если тип соответствует
1. Записывает строку в Clickhouse

Поля бд clickhouse:
- inc
- uuid
- unit_uuid
- state
- state_type
- create_datatime
- expiration_datetime

Отчистка:
1. Если получится через expiration_date будет супер, но нужно обязательно проставлять is_delte или писать скрипт поиска для файлов которых нет

Хранение по типам:
- Числа - Clickhouse
- Текст - Clickhouse
- Изображения - Clickhouse + Minio
- Файлы - Clickhouse + Minio

Например:

Когда нужно 100% разрешение по времени - узнать точную кривую муфельной печи для выведения коэффициентов

### Агрегация

Хранение по типам:
- Числа - Clickhouse

Например:

Cоздание ровных временных рядов с заданным разрешением - датчики температуры, влажности и давления
    
### Видео из изображений

Хранение по типам:
- Изображения - Clickhouse + Minio

Например:

Таймлапсы через esp32 cam
       
### Видео из изображений
1. Размер окна: от 1 минуты до 12 часов, при этом периоды привязаны к 00:00
1. Установка частоты кадров
1. Установка кодека при создании видео из изображений

### Агрегация
1. Размер окна: от 1 минуты до 12 часов, при этом периоды привязаны к 00:00
1. Идёт буферизация за указанное время, до следующего времени после чего происходит вычисление с сохранением в clickhouse:
    - min/max
    - sum
    - avg

## Буферизация
1. Размер пачки данных
    - Хранение N последних записей
    - Хранение временного окн
1. Время накопления пачки данных от 1 минуты до N часов
    - Хранение N последних записей
    - Хранение временного окна

## Сохранение
- скрытый от пользователя этап

1. Расчитывает размер сохраняемых данных
1. Сохраняет данные согласно их типу и политике хранения

## Лимитирование
- скрытый от пользователя этап

1. Для ёмких конвейеров, нужна система лимитирования

## Пример yml

```yml
version: 1.0

pipeline:
  active_period:
    type: "date_range"  # permanent/from_date/to_date/date_range
    start: 2023-11-15T00:00:00Z
    end: 2024-11-15T00:00:00Z

  filters:
    type_input_value: "number" # number/text/image/binary
    type_value_filtering: "whitelist" # null/whitelist/blacklist
        values: [1,2,3,4,5]
    type_value_threshold: "range" # null/min/max/range
        min: -40
        max: 120
    max_rate: "10s" # Ns/Nm/Nh
    last_unique_check: false
    max_size: 10 # in symbols

  transformations:
    - type: "numeric"  # numeric/image/file
      multiplication: true
        coefficient: 0.3
      round: true
        decimal_point: 3
    - type: "image"  # numeric/image/file
      resize: true
        width: 640
        hight: 320
      pixel_density: true
        dpi: 300
      clipping: true
        x: 50
        y: 50
        width: 240
        hight: 120
      format: "jpg" # null/png/jpg/svg/webp
    - type: "file"  # numeric/image/file
      compression: tgz # null/tgz/tar/zip
        wbits: 0
        level: 15

  processing_policy:
    - type: "last_value"
      file_ttl: 86400
    - type: "n_records"
      count_records: 1024  # 1-8192
    - type: "time_window"
      start: 2023-11-15T00:00:00Z
      end: 2024-11-15T00:00:00Z
    - type: "aggregation"
      window_size: "1h"  # 1m, 5m, 1h, 12h
      aggregation_functions: "avg" # avg/min/max/sum
    - type: "video"
      frame_rate_per_second: dynamic # dynamic/Nframe
      codec: H.264/AVC # из ffmpeg

  save_buffering:
    # stage only for n_records and time_window
    - max_items: 10 # 1-2048
    - accumulation_time: 5m # 1m-12h
```

## Ожидания

- Система может накапливать обогащённые данные
- Система может предоставлять эти данные пользователям
