# Система агрегации данных

## Текущее состояние системы
1. Авторизация для подписки и публикации в топики идёт через python, это делается через rest, с хорошей производительностью
    - рест автоматически раскидывается на отдельные воркеры
    - у emqx брокера есть кеширование для авторизаций
2. Есть 2 вида топиков
    - example.com/+/+/+/pepeunit - системные, они забронированы и их поведение стандартизировано в pepeunit
        - Идёт сохранение стандартизированного состояния, обновляются состояния обновлений и тд.
        - Выполняется одним потоком Uvicorn
        - Для топика state сохранение идёт в Postgres
        - Для топика log сохранение идёт в Clickhouse и обновляется время в Postgres
    - example.com/+/pepeunit - принадлежащие Unit
        - Прямое сохранение всего что выдают Unit, в виде текста в Postgres
        - В бд сохраняется только 1 запрос за N секунд по умолчанию 30
3. Общий лимит на обьём информации передаваемой в payload топика берётся из настроек
4. Выполняется одним потоком Uvicorn. Практический потолок 4к запросов в секунду

## Проектное состояние
1. Авторизация топиков остаётся без изменений
2. example.com/+/+/+/pepeunit остаётся в python
    - Разрешаем сохранять не чаще чем лимит backend_state_send_interval - 1 сек. 
    - Попробовать добавить лимит на топик в emqx
3. example.com/+/pepeunit переходит в go приложение
    - Go приложение поддерживает одно клиентское соединение и подписано на все топики вида example.com/+/pepeunit
    - Обрабатывает запросы согласно политикам, которые постоянно синхронизируется с python бекендом
4. Связка python + go должна иметь следующие политики накопления данных:
    - По умолчанию все политики выключенны и агрегация и/или хранение не идёт, такие топики скипаются всегда. Пользователь должен сам своими руками включить одину из политик, потому что в будущем это повлияет на его бабки.
    - Хранение последнего значения
        - Postgres
        - Сохранение 1 сообщения в N сек/минут/часов
        - Например: отлеживать последнее состояние датчика, часто этого достаточно
    - Хранение N последних записей
        - Clickhouse
        - Для ивентовых событий
        - Например: cработка сигнализации или датчика движения
    - Хранение N записей за последние 0-N минут/часов
        - Clickhouse
        - Хранятся все записи в диапазоне от текущего момента до 0-N минут/часов назад
        - C указанием буферизации от 1 минуты до N часов, чтобы не дудосить clickhouse запросами каждую секунду
        - Нужно в местах где нужно 100% разрешение по времени и не нужна агрегация, для сырых данных и внешней аналитики. При этом платить деньги за долговременное хранение всех значений не хочется
        - Например: точный температурный эксперимент в муфельной печи - задача узнать точную кривую для выведения коэффициентов
    - Хранение изображений с накоплением в видео
        - Minio + Clickhouse
        - Сырые изображения приводятся к заданному формату
        - Изображения накапливаются по их общему размеру, числу или времени
        - Изображения мержатся в видео
        - Видео загружется в minio
        - Например: таймлапсы через esp32 cam
    - Хранение файла
        - Minio + Сlickhouse or postgres
        - Аналогично: Хранение последнего значения, Хранение N последних записей, Хранение N записей за последние 0-N минут/часов
        - Возможность сжатия tgz, tar, zip. Для tgz надо настроить обязательно level и wbits
        - Для изображений возможность обрезки и сжатия
        - Добавляется лимитация по объёму
        - Загрузка в minio
        - Напирмер: одиночные изображения, csv с данными
    - Агрегация. С заданной шириной окна агрегации 0-N часов/минут
        - Clickhouse
        - Привязка должна идти к целым часам. 00:00-00:05 для 5 минут или 00:00-01:00 для 1 часа
        - Идёт буферизация за указанное время, до следующего времени после чего происходит вычисление с сохранением в clickhouse:
            - min/max
            - sum
            - avg
        - Например: датчики температуры, нет смысла хранить с разрешением 10 сек, достаточно среднего значения за час или 15 минут
5. Для каждой политики можно задать время действия:
    - от какой-то даты и в дальнейшем постоянными
    - от текущей даты до заданного значения
    - Диапазон времени по датам с часами и минутами
    - Постоянно
5. На стороне python должна быть возможность получать данные от разных типов агрегации через запросы в Clickhouse с разными пагинациями
6. Таблицы clickhose думаю лучше сделать отдельными для каждого рода политики, чтобы агрегационные запросы были эффективнее
7. Везде нужно хранить размер содержимого, чтобы знать общий вес хранения. Он будет влиять на монетизацию в дальнейшем.

## Поддерживаемые политики для разных типов данных:

Типы данных:
1. Числовые int, float:
    - Хранение последнего значения
    - Хранение N последних записей
    - Хранение N записей за последние 0-N минут/часов
    - Агрегация
2. Строки без структуры:
    - Хранение последнего значения
    - Хранение N последних записей
    - Хранение N записей за последние 0-N минут/часов
    - Агрегация
3. Сериализуемый JSON в виде строки:
    - Хранение последнего значения
    - Хранение N последних записей
4. Изображения:
    - Хранение изображений с накоплением в видео
    - Хранение файла
5. Бинарные данные:
    - Хранение файла

## Ожидания

- Воркер Go, берёт на себя задачу обработки потоков данных и их складирование в хранилища
- Бекенд на Python, берёт на себя работу с юзерами, отдачу им всех накопленных данных
- Grafana в будущем позволяет всё это отображать